{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8192\n",
    "data_path='/data/mnist'\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "num_inputs = 28*28\n",
    "num_outputs = 10\n",
    "\n",
    "# Temporal Dynamics\n",
    "num_steps = 30\n",
    "beta = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_outputs, bias=False)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "    def forward(self, x):\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "\n",
    "        spk1_rec = []\n",
    "        mem1_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            spk1_rec.append(spk1)\n",
    "            mem1_rec.append(mem1)\n",
    "\n",
    "        return torch.stack(spk1_rec, dim=0), torch.stack(mem1_rec, dim=0)\n",
    "        \n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = next(iter(train_loader))\n",
    "data = data.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
    "print(data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for testing network on test dataset.\n",
    "\n",
    "def test_acc():\n",
    "  total = 0\n",
    "  correct = 0\n",
    "\n",
    "  test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    net.eval()\n",
    "    for data, targets in test_loader:\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "      \n",
    "      # forward pass\n",
    "      test_spk, _ = net(data.view(data.size(0), -1))\n",
    "\n",
    "      # calculate total accuracy\n",
    "      _, predicted = test_spk.sum(dim=0).max(1)\n",
    "      total += targets.size(0)\n",
    "      correct += (predicted == targets).sum().item()\n",
    "\n",
    "  return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-entropy fitness function for GA\n",
    "\n",
    "def fitness_function(chromosome_input, parameter_input):\n",
    "    \n",
    "    # Loading chromosome onto network\n",
    "    state_dict = net.state_dict()\n",
    "    state_dict[parameter_input] = chromosome_input.clone().detach()\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "    spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
    "\n",
    "    # Initialize the total loss value\n",
    "    loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "\n",
    "    # Sum loss at every step\n",
    "    for step in range(num_steps):\n",
    "        loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "    return loss_val.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crossover function for GA. Produces one off spring per member of population.\n",
    "\n",
    "def crossover(population, row, column):\n",
    "\n",
    "    for i in range(2, int(population_number/2)+1, 2):        \n",
    "        children = torch.zeros(2,row,column, device=device)\n",
    "        crossover_col = torch.randint(0,column,(1,))\n",
    "\n",
    "        for n in range(2):\n",
    "            children[n,:,:crossover_col], children[n,:,crossover_col:] = population[i-2,:,:crossover_col], population[i-1,:,crossover_col:]\n",
    "\n",
    "        population = torch.cat((population,children))\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutation function for GA.\n",
    "\n",
    "def mutation(population, best_chromosome, population_number, row, column, best_prob):\n",
    "    for i in range(0, int(population_number)):\n",
    "        if random.random() < best_prob:\n",
    "            for row_count in range(row):\n",
    "                for column_count in range(column):\n",
    "                    if random.random() < 0.0003:\n",
    "                        if random.random() < 0.5:\n",
    "                            population[i, row_count, column_count] += random.random()*0.5\n",
    "                        else:\n",
    "                            population[i, row_count, column_count] -= random.random()*0.5\n",
    "        else:\n",
    "            population[i,:,:] = best_chromosome[:,:]    # Chance of inserting best solution into population\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop of GA.\n",
    "\n",
    "def evolve(input, population_number, generation_goal, parameter_input):\n",
    "\n",
    "    input_row = input.size()[1]\n",
    "    input_column = input.size()[2]\n",
    "\n",
    "    test_accuracy_hist= []\n",
    "    loss_hist = []\n",
    "\n",
    "    solution_input = torch.zeros(generation_goal, input_row, input_column, device=device)\n",
    "    best_acc = 99999\n",
    "    best_loss_index = 0\n",
    "    best_prob = .98\n",
    "\n",
    "    for evolution_number in range(generation_goal):\n",
    "        \n",
    "        best_acc_gen = 99999\n",
    "        accuracy_generation_list = torch.full((2,int(population_number/2)), 99999)  # List for storing fitness and index of best solutions.\n",
    "        temp_input = torch.zeros(int(population_number/2), input_row, input_column, device=device)  # Used to sort population after fitness score.\n",
    "\n",
    "        for chromosome_number in range(population_number):\n",
    "\n",
    "            accuracy = fitness_function(input[chromosome_number,:,:], parameter_input)\n",
    "                  \n",
    "            if accuracy < best_acc:     #Saving best solution.\n",
    "                best_acc = accuracy\n",
    "                best_loss_index = evolution_number\n",
    "\n",
    "            if accuracy < best_acc_gen:     # Saving best solution of each generation.\n",
    "                best_acc_gen = accuracy\n",
    "                solution_input[evolution_number,:,:] = input[chromosome_number,:,:].detach().clone()\n",
    "                \n",
    "            highest_loss_index = torch.max(accuracy_generation_list, 1)         \n",
    "            \n",
    "            if (accuracy) < highest_loss_index[0][1]:   # Selection of the best solutions of generations for GA.\n",
    "\n",
    "                indice = int(highest_loss_index[1][1])\n",
    "                accuracy_generation_list[0][indice] = chromosome_number\n",
    "                accuracy_generation_list[1][indice] = accuracy\n",
    "\n",
    "        temp_input = torch.zeros((int(population_number/2), input_row, input_column), device=device)\n",
    "\n",
    "        loss_hist.append(best_acc)\n",
    "        \n",
    "        try:\n",
    "            if best_acc_gen > loss_hist[evolution_number - 1]:  #Increases probability of inserting best solution into population if perfomance worsen\n",
    "                best_prob = .9\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        for n in range(int(population_number/2)):       # Sorting the population based on fitness.\n",
    "            index = torch.min(accuracy_generation_list,1)\n",
    "            temp_input[n,:,:] = input[index[1][1],:,:]\n",
    "            accuracy_generation_list[1][index[1][1]] = 99999\n",
    "        \n",
    "        if (evolution_number % 500) == 0:   # Testing the best solution on test dataset every 500th interval.\n",
    "            state_dict = net.state_dict()\n",
    "            state_dict[parameter_input] = solution_input[best_loss_index, :, :]\n",
    "            net.load_state_dict(state_dict)\n",
    "            accuracy_test = test_acc()\n",
    "            test_accuracy_hist.append(accuracy_test)\n",
    "\n",
    "            print(f\"\"\"\n",
    "            Generation:         {evolution_number}/{generation_goal}\n",
    "            Training loss:      {best_acc:.2f}\n",
    "            Test accuracy:      {accuracy_test:.2f}%\\n\"\"\"\n",
    "            )\n",
    "\n",
    "            data, targets = next(iter(train_loader))    # Changes batch every 500th generation.\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            best_acc = 99999          \n",
    "\n",
    "        temp_input = crossover(temp_input, input_row, input_column)\n",
    "        temp_input = mutation(temp_input, solution_input[best_loss_index,:,:], population_number, input_row, input_column, best_prob)\n",
    "\n",
    "        input = temp_input.detach().clone()\n",
    "\n",
    "    state_dict = net.state_dict()\n",
    "    state_dict[parameter_input] = solution_input[generation_goal-1].detach().clone()\n",
    "    net.load_state_dict(state_dict)\n",
    "    \n",
    "    return solution_input, loss_hist\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_number = 8   # Size of population.\n",
    "generation_goal = 10000 # Generation termination goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "\n",
    "    fc1w = torch.randn(population_number, num_outputs, num_inputs, device=device)\n",
    "    mul = torch.tensor([0.01], device=device)\n",
    "    fc1w = torch.multiply(fc1w, mul)\n",
    "\n",
    "    input, loss_hist = evolve(fc1w, population_number, generation_goal, 'fc1.weight')\n",
    "\n",
    "test_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training loss.\n",
    "\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "plt.plot(loss_hist)\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.legend([\"Train Loss\"])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.snn': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "606a12c767200eb5eaada5090c693c32d0ef23b6c09e10a8c668788181180b8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
